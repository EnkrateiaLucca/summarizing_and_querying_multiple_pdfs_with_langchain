{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Multiple PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.2)\n",
    "def summarize_pdfs_from_folder(pdfs_folder):\n",
    "    summaries = []\n",
    "    for pdf_file in glob.glob(pdfs_folder + \"/*.pdf\"):\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        docs = loader.load_and_split()\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summary = chain.run(docs)\n",
    "        print(\"Summary for: \", pdf_file)\n",
    "        print(summary)\n",
    "        print(\"\\n\")\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_summary(pdf_folder, custom_prompt):\n",
    "    summaries = []\n",
    "    for pdf_file in glob.glob(pdf_folder + \"/*.pdf\"):\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        docs = loader.load_and_split()\n",
    "        prompt_template = custom_prompt + \"\"\"\n",
    "\n",
    "        {text}\n",
    "\n",
    "        SUMMARY:\"\"\"\n",
    "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\", \n",
    "                                    map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "        summary_output = chain({\"input_documents\": docs},return_only_outputs=True)[\"output_text\"]\n",
    "        summaries.append(summary_output)\n",
    "        \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for:  ./pdfs/prompt_vision_language_models_paper.pdf\n",
      "\n",
      "\n",
      "This paper presents CoOp, a few-shot learning method that uses learnable context vectors to optimize pre-trained vision-language models for downstream image recognition tasks. Experiments on 11 datasets show that CoOp outperforms hand-crafted prompts and the linear probe model, and is robust to domain shifts. The paper also discusses various research papers related to computer vision, including topics such as natural adversarial examples, scaling up visual and vision-language representation learning, visual prompt tuning, predicting deep zero-shot convolutional neural networks, parameter-efficient prompt tuning, learning visual n-grams from web data, optimizing continuous prompts for generation, pre-training with noisy text supervision, measuring robustness to natural distribution shifts, and learning robust global representations.\n",
      "\n",
      "\n",
      "Summary for:  ./pdfs/scaling_transformer_paper.pdf\n",
      " This paper presents the Recurrent Memory Transformer (RMT) model, which is designed to process sequences longer than 1 million tokens with a single GPU. Experiments demonstrate the effectiveness of the approach, which holds potential to enhance long-term dependency handling in natural language understanding and generation tasks. The paper also reviews a variety of works related to neural networks and natural language processing, such as Big Bird and Opt, two Transformer-based models for longer sequences.\n",
      "\n",
      "\n",
      "Summary for:  ./pdfs/llm_planning_paper.pdf\n",
      " This paper introduces LLM+P, a framework that combines the strengths of large language models (LLMs) and classical planners to solve long-horizon planning problems. Experiments show that LLM+P is able to provide optimal solutions while LLMs fail to provide even feasible plans. It uses a PDDL representation to convert a natural language prompt into a plan, which is then translated back to natural language using the LLM. Results show that LLM+P is successful in all domains, while LLM-AS-P fails in most domains. Future work includes enabling the LLM to auto-detect when and how to apply LLM+P and reducing LLM+Pâ€™s dependency on information by humans.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaries = summarize_pdfs_from_folder(\"./pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM_PROMPT = \"Write a concise summary of the following paper with this structure: Problem being solved; Approach; Main results; Main Discussion Points\"\n",
    "# custom_summaries = custom_summary(\"./pdfs\", custom_prompt=CUSTOM_PROMPT)\n",
    "# # Save all summaries into one .txt file\n",
    "# with open(\"custom_summaries.txt\", \"w\") as f:\n",
    "#     for summary in custom_summaries:\n",
    "#         f.write(summary + \"\\n\"*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all summaries into one .txt file\n",
    "with open(\"summaries.txt\", \"w\") as f:\n",
    "    for summary in summaries:\n",
    "        f.write(summary + \"\\n\"*3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Multiple PDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(\"./pdfs/\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Create the vector store index\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The core idea behind the CoOP paper is to model a prompt's context words with learnable vectors while keeping the entire pre-trained parameters fixed, in order to adapt CLIP-like vision-language models for downstream image recognition tasks.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the core idea behind the CoOP (context optimization) paper?\"\n",
    "\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The central idea is to use the Recurrent Memory Transformer (RMT) architecture to extend the context length of BERT, allowing it to store and process both local and global information across up to 2 million tokens.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the central idea that can allow for scaling transformers to 1 million tokens?\"\n",
    "\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"According to the LLM+P paper, how do you empower large language models with optimal planning profficiency?\"\n",
    "\n",
    "index.query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
